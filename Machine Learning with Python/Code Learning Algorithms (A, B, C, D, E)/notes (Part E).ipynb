{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification:\n",
    "\n",
    "While Linear Regression is used to predict a numeric value, classification is used to separate data into different labels. \n",
    "\n",
    "In this example, I will use the TensorFlow estimator to classify flowers. \n",
    "\n",
    "Sourced mainly from: https://www.tensorflow.org/tutorials/estimator/premade\n",
    "\n",
    "Note that there won't be as many notes, as most of it is covered in previous lessons (and are therefore in the previous Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing various libraries into this session:\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set:\n",
    "This specific dataset will seperate flowers into 3 different classes/species:\n",
    "* Setosa\n",
    "* Versicolor\n",
    "* Virginica\n",
    "\n",
    "Information is given for each flower, this includes:\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length\n",
    "* Petal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating some constants:\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "\n",
    "\n",
    "#Here we are using Keras (a module from within TensorFlow) to grab the datasets and read them into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() #First 5 lines of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the datasets, split out the labels, which the model will be trained to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "# The label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the shape to make sure it has the expected amount of entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape # Expected to have 120 entries (i.e. rows) + 4 features (i.e. columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Function:\n",
    "\n",
    "This input function is a little easier to understand compared to the one used in the Linear Regression example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Columns:\n",
    "\n",
    "Here I'll put in the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model:\n",
    "Now you are able to choose a model. For Classification, there are a few estimators/models that you can pick from, some examples are:\n",
    "* ``tf.estimator.DNNClassifier`` for deep models that perform multi-class classification.\n",
    "* ``tf.estimator.DNNLinearCombinedClassifier`` for wide & deep models.\n",
    "* ``tf.estimator.LinearClassifier`` for classifiers based on linear models.\n",
    "\n",
    "You are able to choose either from a deep neural network (DDN) or from a Linear model. As there is unlikely to be a linear relationship, it makes sense to use the deep neural network for this use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmph65luoml\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmph65luoml', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers (middle layers) of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "Now it is finally time to start training this Machine Learning model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lambda Function**:\n",
    "The lambda function allows for the creation of a function within one line.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\n"
     ]
    }
   ],
   "source": [
    "x = lambda: print('this is a test')\n",
    "\n",
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 16:38:50.347684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:38:50.348169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:38:50.348473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:38:50.348857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:38:50.349187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:38:50.349921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 928 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 950, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmph65luoml/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.235672, step = 0\n",
      "INFO:tensorflow:global_step/sec: 228.229\n",
      "INFO:tensorflow:loss = 1.038756, step = 100 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.048\n",
      "INFO:tensorflow:loss = 0.98591965, step = 200 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.183\n",
      "INFO:tensorflow:loss = 0.95637524, step = 300 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.492\n",
      "INFO:tensorflow:loss = 0.95205355, step = 400 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.471\n",
      "INFO:tensorflow:loss = 0.9059025, step = 500 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.88\n",
      "INFO:tensorflow:loss = 0.89537674, step = 600 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.974\n",
      "INFO:tensorflow:loss = 0.8911496, step = 700 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.584\n",
      "INFO:tensorflow:loss = 0.88835716, step = 800 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.609\n",
      "INFO:tensorflow:loss = 0.8481572, step = 900 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.796\n",
      "INFO:tensorflow:loss = 0.85871893, step = 1000 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.911\n",
      "INFO:tensorflow:loss = 0.82316405, step = 1100 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.432\n",
      "INFO:tensorflow:loss = 0.83027464, step = 1200 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.363\n",
      "INFO:tensorflow:loss = 0.83718926, step = 1300 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.956\n",
      "INFO:tensorflow:loss = 0.80397534, step = 1400 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.222\n",
      "INFO:tensorflow:loss = 0.81165475, step = 1500 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.825\n",
      "INFO:tensorflow:loss = 0.7840489, step = 1600 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.562\n",
      "INFO:tensorflow:loss = 0.76794887, step = 1700 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.591\n",
      "INFO:tensorflow:loss = 0.75621223, step = 1800 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.38\n",
      "INFO:tensorflow:loss = 0.72833544, step = 1900 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.787\n",
      "INFO:tensorflow:loss = 0.7169278, step = 2000 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.104\n",
      "INFO:tensorflow:loss = 0.72297865, step = 2100 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.261\n",
      "INFO:tensorflow:loss = 0.7055079, step = 2200 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.573\n",
      "INFO:tensorflow:loss = 0.7119731, step = 2300 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.572\n",
      "INFO:tensorflow:loss = 0.6931547, step = 2400 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.732\n",
      "INFO:tensorflow:loss = 0.6767741, step = 2500 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.583\n",
      "INFO:tensorflow:loss = 0.65280044, step = 2600 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.639\n",
      "INFO:tensorflow:loss = 0.6682779, step = 2700 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.718\n",
      "INFO:tensorflow:loss = 0.59995127, step = 2800 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.737\n",
      "INFO:tensorflow:loss = 0.5551486, step = 2900 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.391\n",
      "INFO:tensorflow:loss = 0.54423434, step = 3000 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.683\n",
      "INFO:tensorflow:loss = 0.5238535, step = 3100 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.896\n",
      "INFO:tensorflow:loss = 0.5122324, step = 3200 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.564\n",
      "INFO:tensorflow:loss = 0.4995868, step = 3300 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.252\n",
      "INFO:tensorflow:loss = 0.50985426, step = 3400 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.203\n",
      "INFO:tensorflow:loss = 0.49229187, step = 3500 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.096\n",
      "INFO:tensorflow:loss = 0.47241572, step = 3600 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.797\n",
      "INFO:tensorflow:loss = 0.46968764, step = 3700 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.017\n",
      "INFO:tensorflow:loss = 0.45820048, step = 3800 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.586\n",
      "INFO:tensorflow:loss = 0.44465038, step = 3900 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.115\n",
      "INFO:tensorflow:loss = 0.43782145, step = 4000 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.344\n",
      "INFO:tensorflow:loss = 0.43252397, step = 4100 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.208\n",
      "INFO:tensorflow:loss = 0.42603052, step = 4200 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.353\n",
      "INFO:tensorflow:loss = 0.42888153, step = 4300 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.299\n",
      "INFO:tensorflow:loss = 0.4100666, step = 4400 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.459\n",
      "INFO:tensorflow:loss = 0.40375066, step = 4500 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.593\n",
      "INFO:tensorflow:loss = 0.40239513, step = 4600 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.716\n",
      "INFO:tensorflow:loss = 0.40619949, step = 4700 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.421\n",
      "INFO:tensorflow:loss = 0.39494163, step = 4800 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.47\n",
      "INFO:tensorflow:loss = 0.39064318, step = 4900 (0.376 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmph65luoml/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.3748266.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f65ec5c9de0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True), #lambda means a one line function: everything afterwards works as a function\n",
    "    steps=5000) #similar to an epoch, although it goes through 5000 iterations.\n",
    "\n",
    "#This output will be very long! Just wanted to keep this in to show how the training process looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the trained model:\n",
    "After the model has been trained, you can get some statistics on it's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions:\n",
    "\n",
    "From this trained model, you are able to predict the species of an Iris flower based on some measurements. You are able to do with with a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmph65luoml/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"Setosa\" (79.2%), expected \"Setosa\"\n",
      "\n",
      "\n",
      "Prediction is \"Versicolor\" (53.9%), expected \"Versicolor\"\n",
      "\n",
      "\n",
      "Prediction is \"Virginica\" (64.2%), expected \"Virginica\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 16:59:11.314377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:59:11.314854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:59:11.315292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:59:11.315752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:59:11.316242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:59:11.316776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 928 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 950, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from the model (from TensorFlow website)\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))\n",
    "\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('\\n'+'Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    #Converts the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "#For each feature, wait until you receive a valid response. \n",
    "print(\"Please type in numerical values as prompted:\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + \": \")\n",
    "        if not val.isdigit(): valid = False\n",
    "\n",
    "\n",
    "#add any valid inputs to a list\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilites'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
