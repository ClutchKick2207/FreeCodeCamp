{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification:\n",
    "\n",
    "While Linear Regression is used to predict a numeric value, classification is used to separate data into different labels. \n",
    "\n",
    "In this example, I will use the TensorFlow estimator to classify flowers. \n",
    "\n",
    "Sourced mainly from: https://www.tensorflow.org/tutorials/estimator/premade\n",
    "\n",
    "Note that there won't be as many notes, as most of it is covered in previous lessons (and are therefore in the previous Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing various libraries into this session:\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set:\n",
    "This specific dataset will seperate flowers into 3 different classes/species:\n",
    "* Setosa\n",
    "* Versicolor\n",
    "* Virginica\n",
    "\n",
    "Information is given for each flower, this includes:\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length\n",
    "* Petal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating some constants:\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "\n",
    "\n",
    "#Here we are using Keras (a module from within TensorFlow) to grab the datasets and read them into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() #First 5 lines of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the datasets, split out the labels, which the model will be trained to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "# The label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the shape to make sure it has the expected amount of entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape # Expected to have 120 entries (i.e. rows) + 4 features (i.e. columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Function:\n",
    "\n",
    "This input function is a little easier to understand compared to the one used in the Linear Regression example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Columns:\n",
    "\n",
    "Here I'll put in the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model:\n",
    "Now you are able to choose a model. For Classification, there are a few estimators/models that you can pick from, some examples are:\n",
    "* ``tf.estimator.DNNClassifier`` for deep models that perform multi-class classification.\n",
    "* ``tf.estimator.DNNLinearCombinedClassifier`` for wide & deep models.\n",
    "* ``tf.estimator.LinearClassifier`` for classifiers based on linear models.\n",
    "\n",
    "You are able to choose either from a deep neural network (DDN) or from a Linear model. As there is unlikely to be a linear relationship, it makes sense to use the deep neural network for this use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp91ahzimm\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp91ahzimm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers (middle layers) of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "Now it is finally time to start training this Machine Learning model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lambda Function**:\n",
    "The lambda function allows for the creation of a function within one line.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\n"
     ]
    }
   ],
   "source": [
    "x = lambda: print('this is a test')\n",
    "\n",
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp91ahzimm/model.ckpt-5000\n",
      "WARNING:tensorflow:From /usr/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1165: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 16:27:17.335333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:27:17.335781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:27:17.336136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:27:17.336581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:27:17.336935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:27:17.337233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 928 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 950, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp91ahzimm/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:loss = 0.5976476, step = 5000\n",
      "INFO:tensorflow:global_step/sec: 191.176\n",
      "INFO:tensorflow:loss = 0.587281, step = 5100 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.233\n",
      "INFO:tensorflow:loss = 0.57784796, step = 5200 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.566\n",
      "INFO:tensorflow:loss = 0.58259004, step = 5300 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.612\n",
      "INFO:tensorflow:loss = 0.56883466, step = 5400 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.583\n",
      "INFO:tensorflow:loss = 0.57379997, step = 5500 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.122\n",
      "INFO:tensorflow:loss = 0.570787, step = 5600 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.697\n",
      "INFO:tensorflow:loss = 0.5670659, step = 5700 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.536\n",
      "INFO:tensorflow:loss = 0.53840435, step = 5800 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.403\n",
      "INFO:tensorflow:loss = 0.54879135, step = 5900 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.861\n",
      "INFO:tensorflow:loss = 0.5464426, step = 6000 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.68\n",
      "INFO:tensorflow:loss = 0.5250659, step = 6100 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.786\n",
      "INFO:tensorflow:loss = 0.53580904, step = 6200 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.704\n",
      "INFO:tensorflow:loss = 0.51373196, step = 6300 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.771\n",
      "INFO:tensorflow:loss = 0.5282857, step = 6400 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.169\n",
      "INFO:tensorflow:loss = 0.5147025, step = 6500 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.344\n",
      "INFO:tensorflow:loss = 0.5026458, step = 6600 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.432\n",
      "INFO:tensorflow:loss = 0.5194938, step = 6700 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.927\n",
      "INFO:tensorflow:loss = 0.49941954, step = 6800 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.505\n",
      "INFO:tensorflow:loss = 0.48683375, step = 6900 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.399\n",
      "INFO:tensorflow:loss = 0.47854203, step = 7000 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.314\n",
      "INFO:tensorflow:loss = 0.49412465, step = 7100 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.159\n",
      "INFO:tensorflow:loss = 0.48855117, step = 7200 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.747\n",
      "INFO:tensorflow:loss = 0.47765088, step = 7300 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.018\n",
      "INFO:tensorflow:loss = 0.4764586, step = 7400 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.945\n",
      "INFO:tensorflow:loss = 0.48477077, step = 7500 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.757\n",
      "INFO:tensorflow:loss = 0.47367668, step = 7600 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.528\n",
      "INFO:tensorflow:loss = 0.4668738, step = 7700 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.723\n",
      "INFO:tensorflow:loss = 0.46339464, step = 7800 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.183\n",
      "INFO:tensorflow:loss = 0.45292228, step = 7900 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.409\n",
      "INFO:tensorflow:loss = 0.4579433, step = 8000 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.484\n",
      "INFO:tensorflow:loss = 0.44098905, step = 8100 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.768\n",
      "INFO:tensorflow:loss = 0.4598827, step = 8200 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.706\n",
      "INFO:tensorflow:loss = 0.45185423, step = 8300 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.814\n",
      "INFO:tensorflow:loss = 0.43783468, step = 8400 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.042\n",
      "INFO:tensorflow:loss = 0.43835858, step = 8500 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.614\n",
      "INFO:tensorflow:loss = 0.43367833, step = 8600 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.252\n",
      "INFO:tensorflow:loss = 0.43671972, step = 8700 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.424\n",
      "INFO:tensorflow:loss = 0.43049014, step = 8800 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.188\n",
      "INFO:tensorflow:loss = 0.42707625, step = 8900 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.507\n",
      "INFO:tensorflow:loss = 0.42049626, step = 9000 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.426\n",
      "INFO:tensorflow:loss = 0.41368973, step = 9100 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.325\n",
      "INFO:tensorflow:loss = 0.4151453, step = 9200 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.82\n",
      "INFO:tensorflow:loss = 0.41232124, step = 9300 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.323\n",
      "INFO:tensorflow:loss = 0.41036618, step = 9400 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.136\n",
      "INFO:tensorflow:loss = 0.40721244, step = 9500 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.875\n",
      "INFO:tensorflow:loss = 0.39527088, step = 9600 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.185\n",
      "INFO:tensorflow:loss = 0.3894316, step = 9700 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.109\n",
      "INFO:tensorflow:loss = 0.39821565, step = 9800 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.513\n",
      "INFO:tensorflow:loss = 0.3892971, step = 9900 (0.382 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp91ahzimm/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:Loss for final step: 0.3998063.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f668aa2ff70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True), #lambda means a one line function: everything afterwards works as a function\n",
    "    steps=5000) #similar to an epoch, although it goes through 5000 iterations.\n",
    "\n",
    "#prepare! The output below will be very long! I wanted to keep it in here so anyone who can't train on a GPU or in general can see all the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the trained model:\n",
    "After the model has been trained, you can get some statistics on it's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-01-18T16:31:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp91ahzimm/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 16:31:32.646145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:31:32.646600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:31:32.646954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:31:32.647389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:31:32.647769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 16:31:32.648094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 928 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 950, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 0.65375s\n",
      "INFO:tensorflow:Finished evaluation at 2022-01-18-16:31:33\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.93333334, average_loss = 0.46332607, global_step = 10000, loss = 0.46332607\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmp91ahzimm/model.ckpt-10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93333334,\n",
       " 'average_loss': 0.46332607,\n",
       " 'loss': 0.46332607,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
